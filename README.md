# LLM-Powered Autonomous Data Insight Generator

An interactive Streamlit-based web application that acts like a **Senior Data Scientist Agent** to generate advanced data insights, visualizations, and answer questions â€” powered by **Gemma (via Ollama locally)** and **Groq (cloud)**.

---

## Features

- Upload structured data (`.csv`, `.xlsx`, `.json`, `.xml`)
- Auto-generates insights across 7 categories:
  - Performance & Accuracy Insights
  - Question-Specific Insights
  - Attempt & Behavioral Insights
  - Comparative & Demographic Insights
  - Question Design & Learning Insights
  - Advanced Statistical Insights
  - Actionable Recommendations
- Advanced auto visualizations using Plotly
- Intelligent Q&A on your dataset
- Dual-model integration:
  - `Gemma` (offline via Ollama)
  - `Groq` (cloud-based, faster inference)

---



## Folder Structure

GenAI/

â”‚

â”œâ”€â”€ app.py                          # Streamlit app

â”œâ”€â”€ prompts/

â”‚   â””â”€â”€ system_prompts.txt          # LLM system instructions

â”œâ”€â”€ models/

â”‚   â””â”€â”€ local_model.py              # Model interface

â”œâ”€â”€ utils/

â”‚   â”œâ”€â”€  **init** .py

â”‚   â”œâ”€â”€ chat_handler.py             # Handles chat with LLM

â”‚   â”œâ”€â”€ data_cleaner.py             # Cleaning utilities

â”‚   â”œâ”€â”€ file_loader.py              # File parsing

â”‚   â”œâ”€â”€ groq_handler.py             # Groq-based inference

â”‚   â”œâ”€â”€ insight_generator.py        # Prompt and generate insights

â”‚   â”œâ”€â”€ ollama_handler.py           # Gemma (local model) handler

â”‚   â”œâ”€â”€ prompt_engine.py            # Prompt formatter

â”‚   â”œâ”€â”€ rag_engine.py               # ðŸ”„ Future integration (RAG)

â”‚   â””â”€â”€ visualizer.py               # Plotting functions
